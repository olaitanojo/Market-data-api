# üöÄ Market Data API - Deployment Guide

> **Professional deployment guide for the Market Data API with multi-source integration, WebSocket streaming, and high-performance architecture.**

## üìã Table of Contents

1. [Quick Start](#quick-start)
2. [Local Development](#local-development)
3. [Docker Deployment](#docker-deployment)
4. [Cloud Deployment](#cloud-deployment)
5. [Load Balancing & Scaling](#load-balancing--scaling)
6. [Configuration](#configuration)
7. [Monitoring & Performance](#monitoring--performance)
8. [Security](#security)
9. [Troubleshooting](#troubleshooting)

---

## üèÉ‚Äç‚ôÇÔ∏è Quick Start

### Prerequisites
- Python 3.8+
- Redis (for caching)
- API keys for data sources (Alpha Vantage, IEX, etc.)
- WebSocket support

### 1-Minute Setup
```bash
# Clone and setup
git clone https://github.com/olaitanojo/market-data-api.git
cd market-data-api
pip install -r requirements.txt

# Setup environment
cp .env.example .env
# Edit .env with your API keys

# Run API server
python app.py
# API available at http://localhost:8000
# WebSocket at ws://localhost:8001
```

---

## üíª Local Development

### Environment Setup
```bash
# Create virtual environment
python -m venv api_env
source api_env/bin/activate  # Windows: api_env\Scripts\activate

# Install core dependencies
pip install fastapi uvicorn websockets redis
pip install requests aiohttp asyncio pandas numpy

# Install data source libraries
pip install alpha-vantage yfinance polygon-api-client

# Install development tools
pip install pytest pytest-asyncio black flake8 httpx
```

### Configuration
```python
# config.py
import os
from typing import Dict, Any

class Settings:
    # API Configuration
    API_HOST: str = os.getenv("API_HOST", "0.0.0.0")
    API_PORT: int = int(os.getenv("API_PORT", "8000"))
    WS_PORT: int = int(os.getenv("WS_PORT", "8001"))
    
    # Redis Configuration
    REDIS_URL: str = os.getenv("REDIS_URL", "redis://localhost:6379")
    CACHE_TTL: int = int(os.getenv("CACHE_TTL", "300"))
    
    # API Keys
    ALPHA_VANTAGE_KEY: str = os.getenv("ALPHA_VANTAGE_KEY", "")
    IEX_TOKEN: str = os.getenv("IEX_TOKEN", "")
    POLYGON_KEY: str = os.getenv("POLYGON_KEY", "")
    QUANDL_KEY: str = os.getenv("QUANDL_KEY", "")
    
    # Rate Limiting
    RATE_LIMIT_REQUESTS: int = int(os.getenv("RATE_LIMIT_REQUESTS", "100"))
    RATE_LIMIT_WINDOW: int = int(os.getenv("RATE_LIMIT_WINDOW", "60"))
    
    # WebSocket Configuration
    WS_MAX_CONNECTIONS: int = int(os.getenv("WS_MAX_CONNECTIONS", "1000"))
    WS_HEARTBEAT_INTERVAL: int = int(os.getenv("WS_HEARTBEAT_INTERVAL", "30"))
```

### Development Server
```bash
# Run development server with auto-reload
uvicorn app:app --reload --host 0.0.0.0 --port 8000

# Run WebSocket server separately
python websocket_server.py

# Run tests
pytest tests/ -v

# Code formatting
black . && flake8 .
```

---

## üê≥ Docker Deployment

### Dockerfile
```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m apiuser && chown -R apiuser:apiuser /app
USER apiuser

# Expose ports
EXPOSE 8000 8001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Start both API and WebSocket servers
CMD ["python", "start_servers.py"]
```

### Multi-Stage Dockerfile (Production)
```dockerfile
# Build stage
FROM python:3.9-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y gcc g++ && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# Production stage
FROM python:3.9-slim

WORKDIR /app

# Install runtime dependencies
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

# Copy Python dependencies from builder stage
COPY --from=builder /root/.local /root/.local

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m apiuser && chown -R apiuser:apiuser /app
USER apiuser

# Make sure scripts in .local are usable
ENV PATH=/root/.local/bin:$PATH

EXPOSE 8000 8001

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

CMD ["gunicorn", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000", "--workers", "4", "app:app"]
```

### Docker Compose
```yaml
version: '3.8'

services:
  api:
    build: .
    container_name: market-data-api
    ports:
      - "8000:8000"
      - "8001:8001"
    environment:
      - REDIS_URL=redis://redis:6379
      - ALPHA_VANTAGE_KEY=${ALPHA_VANTAGE_KEY}
      - IEX_TOKEN=${IEX_TOKEN}
      - POLYGON_KEY=${POLYGON_KEY}
    volumes:
      - ./logs:/app/logs
      - ./cache:/app/cache
    depends_on:
      - redis
      - nginx
    restart: unless-stopped
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    
  redis:
    image: redis:7-alpine
    container_name: market-data-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    container_name: market-data-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./nginx/logs:/var/log/nginx
    depends_on:
      - api
    restart: unless-stopped
    
  prometheus:
    image: prom/prometheus:latest
    container_name: market-data-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped
    
  grafana:
    image: grafana/grafana:latest
    container_name: market-data-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    restart: unless-stopped

volumes:
  redis_data:
  prometheus_data:
  grafana_data:
```

### Requirements.txt
```txt
# Core API Framework
fastapi==0.104.1
uvicorn[standard]==0.24.0
gunicorn==21.2.0

# HTTP and WebSocket
websockets==12.0
aiohttp==3.9.1
httpx==0.25.2

# Data Processing
pandas==2.1.3
numpy==1.24.3
asyncio==3.4.3

# Caching and Database
redis==5.0.1
aioredis==2.0.1

# Financial Data APIs
alpha-vantage==2.3.1
yfinance==0.2.24
polygon-api-client==1.13.0
quandl==3.7.0

# Rate Limiting and Security
slowapi==0.1.9
python-jose[cryptography]==3.3.0

# Monitoring and Logging
prometheus-client==0.19.0
structlog==23.2.0

# Utilities
python-dotenv==1.0.0
pydantic==2.5.0
```

---

## ‚òÅÔ∏è Cloud Deployment

### AWS ECS with Application Load Balancer

#### Task Definition
```json
{
  "family": "market-data-api",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "1024",
  "memory": "2048",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "containerDefinitions": [
    {
      "name": "api",
      "image": "your-ecr-repo/market-data-api:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        },
        {
          "containerPort": 8001,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {"name": "ENVIRONMENT", "value": "production"},
        {"name": "REDIS_URL", "value": "redis://elasticache-endpoint:6379"}
      ],
      "secrets": [
        {"name": "ALPHA_VANTAGE_KEY", "valueFrom": "arn:aws:secretsmanager:region:account:secret:api-keys"},
        {"name": "IEX_TOKEN", "valueFrom": "arn:aws:secretsmanager:region:account:secret:api-keys"}
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/market-data-api",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

#### CloudFormation Template
```yaml
AWSTemplateFormatVersion: '2010-09-09'

Resources:
  # ECS Cluster
  MarketDataCluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: market-data-api-cluster
      CapacityProviders:
        - FARGATE
        - FARGATE_SPOT
      
  # Application Load Balancer
  ALB:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: market-data-alb
      Scheme: internet-facing
      Type: application
      Subnets: !Ref PublicSubnets
      SecurityGroups:
        - !Ref ALBSecurityGroup
      
  # Target Groups
  APITargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: market-data-api-tg
      Port: 8000
      Protocol: HTTP
      VpcId: !Ref VPC
      TargetType: ip
      HealthCheckPath: /health
      HealthCheckProtocol: HTTP
      
  WSTargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: market-data-ws-tg
      Port: 8001
      Protocol: HTTP
      VpcId: !Ref VPC
      TargetType: ip
      
  # ElastiCache for Redis
  RedisCluster:
    Type: AWS::ElastiCache::ReplicationGroup
    Properties:
      ReplicationGroupDescription: Market Data API Cache
      NumCacheClusters: 2
      Engine: redis
      CacheNodeType: cache.t3.micro
      SecurityGroupIds:
        - !Ref RedisSecurityGroup
      SubnetGroupName: !Ref RedisSubnetGroup
```

### Google Cloud Run with Load Balancer
```bash
# Build and push to Container Registry
docker build -t gcr.io/PROJECT_ID/market-data-api .
docker push gcr.io/PROJECT_ID/market-data-api

# Deploy API service
gcloud run deploy market-data-api \
  --image gcr.io/PROJECT_ID/market-data-api \
  --platform managed \
  --region us-central1 \
  --memory 1Gi \
  --cpu 2 \
  --max-instances 20 \
  --min-instances 2 \
  --port 8000 \
  --set-env-vars REDIS_URL=redis://redis-instance-ip:6379 \
  --set-secrets ALPHA_VANTAGE_KEY=api-keys:ALPHA_VANTAGE_KEY \
  --allow-unauthenticated

# Deploy WebSocket service separately
gcloud run deploy market-data-ws \
  --image gcr.io/PROJECT_ID/market-data-api \
  --platform managed \
  --region us-central1 \
  --memory 512Mi \
  --cpu 1 \
  --max-instances 10 \
  --port 8001 \
  --command websocket_server.py
```

### Azure Container Apps
```bash
# Create resource group
az group create --name market-data-rg --location eastus

# Create container app environment
az containerapp env create \
  --name market-data-env \
  --resource-group market-data-rg \
  --location eastus

# Create Redis cache
az redis create \
  --name market-data-redis \
  --resource-group market-data-rg \
  --location eastus \
  --sku Basic \
  --vm-size c0

# Deploy API
az containerapp create \
  --name market-data-api \
  --resource-group market-data-rg \
  --environment market-data-env \
  --image your-registry/market-data-api:latest \
  --target-port 8000 \
  --ingress external \
  --min-replicas 2 \
  --max-replicas 20 \
  --cpu 1.0 \
  --memory 2.0Gi
```

---

## ‚öñÔ∏è Load Balancing & Scaling

### Nginx Configuration
```nginx
upstream api_backend {
    least_conn;
    server api1:8000 max_fails=3 fail_timeout=30s;
    server api2:8000 max_fails=3 fail_timeout=30s;
    server api3:8000 max_fails=3 fail_timeout=30s;
}

upstream websocket_backend {
    ip_hash;  # Sticky sessions for WebSocket
    server ws1:8001;
    server ws2:8001;
    server ws3:8001;
}

# Rate limiting
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
limit_req_zone $binary_remote_addr zone=ws_limit:10m rate=5r/s;

server {
    listen 80;
    server_name api.yourdomain.com;
    
    # API endpoints
    location /api/ {
        limit_req zone=api_limit burst=20 nodelay;
        
        proxy_pass http://api_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Caching for static data
        location ~* ^/api/(stocks|crypto)/(.+)/(info|profile)$ {
            proxy_pass http://api_backend;
            proxy_cache api_cache;
            proxy_cache_valid 200 5m;
            add_header X-Cache-Status $upstream_cache_status;
        }
    }
    
    # WebSocket endpoints
    location /ws {
        limit_req zone=ws_limit burst=10 nodelay;
        
        proxy_pass http://websocket_backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_read_timeout 86400;
    }
    
    # Health check
    location /health {
        proxy_pass http://api_backend;
        access_log off;
    }
}

# Cache configuration
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m max_size=1g inactive=60m use_temp_path=off;
```

### Horizontal Pod Autoscaler (Kubernetes)
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: market-data-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: market-data-api
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
```

---

## ‚öôÔ∏è Configuration

### Environment Variables
```bash
# API Configuration
export API_HOST=0.0.0.0
export API_PORT=8000
export WS_PORT=8001
export WORKERS=4

# Data Sources
export ALPHA_VANTAGE_KEY=your-key
export IEX_TOKEN=your-token
export POLYGON_KEY=your-key
export QUANDL_KEY=your-key

# Caching
export REDIS_URL=redis://localhost:6379
export CACHE_TTL=300
export CACHE_MAX_SIZE=1000

# Rate Limiting
export RATE_LIMIT_REQUESTS=100
export RATE_LIMIT_WINDOW=60

# WebSocket
export WS_MAX_CONNECTIONS=1000
export WS_HEARTBEAT_INTERVAL=30

# Monitoring
export PROMETHEUS_PORT=8080
export LOG_LEVEL=INFO
```

### Advanced Configuration
```python
# settings.py
from pydantic import BaseSettings
from typing import Dict, List

class Settings(BaseSettings):
    # API Configuration
    api_title: str = "Market Data API"
    api_version: str = "2.0.0"
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    
    # Data Sources Configuration
    data_sources: Dict[str, Dict] = {
        "alpha_vantage": {
            "base_url": "https://www.alphavantage.co/query",
            "rate_limit": 5,  # requests per minute
            "timeout": 30
        },
        "iex": {
            "base_url": "https://cloud.iexapis.com/stable",
            "rate_limit": 100,
            "timeout": 10
        },
        "polygon": {
            "base_url": "https://api.polygon.io",
            "rate_limit": 5,
            "timeout": 30
        }
    }
    
    # Caching Strategy
    cache_config: Dict[str, int] = {
        "stock_quotes": 60,       # 1 minute
        "stock_info": 3600,       # 1 hour
        "market_status": 300,     # 5 minutes
        "historical_data": 1800   # 30 minutes
    }
    
    # WebSocket Configuration
    websocket_settings: Dict = {
        "max_connections": 1000,
        "heartbeat_interval": 30,
        "max_message_size": 65536,
        "compression": "deflate"
    }
    
    class Config:
        env_file = ".env"
```

---

## üìä Monitoring & Performance

### Health Check Implementation
```python
from fastapi import FastAPI, HTTPException
from datetime import datetime
import redis
import asyncio
import psutil

app = FastAPI()

@app.get("/health")
async def health_check():
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "2.0.0",
        "services": {},
        "metrics": {}
    }
    
    # Redis health check
    try:
        r = redis.Redis.from_url(settings.REDIS_URL)
        r.ping()
        health_status["services"]["redis"] = "healthy"
    except Exception as e:
        health_status["services"]["redis"] = f"unhealthy: {str(e)}"
        health_status["status"] = "unhealthy"
    
    # Data source health checks
    for source, config in settings.data_sources.items():
        try:
            # Implement specific health check for each source
            await check_data_source_health(source, config)
            health_status["services"][source] = "healthy"
        except Exception as e:
            health_status["services"][source] = f"unhealthy: {str(e)}"
    
    # System metrics
    health_status["metrics"] = {
        "cpu_percent": psutil.cpu_percent(),
        "memory_percent": psutil.virtual_memory().percent,
        "active_connections": get_active_ws_connections(),
        "requests_per_minute": get_request_rate(),
        "cache_hit_rate": get_cache_hit_rate()
    }
    
    return health_status

@app.get("/metrics")
async def prometheus_metrics():
    """Prometheus metrics endpoint"""
    metrics = generate_prometheus_metrics()
    return Response(content=metrics, media_type="text/plain")
```

### Prometheus Metrics
```python
from prometheus_client import Counter, Histogram, Gauge, generate_latest

# Define metrics
REQUEST_COUNT = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'API request duration')
ACTIVE_CONNECTIONS = Gauge('websocket_connections_active', 'Active WebSocket connections')
CACHE_HIT_RATE = Gauge('cache_hit_rate', 'Cache hit rate percentage')
DATA_SOURCE_ERRORS = Counter('data_source_errors_total', 'Data source errors', ['source'])

def generate_prometheus_metrics():
    return generate_latest()
```

### Logging Configuration
```python
import structlog
import logging
from datetime import datetime

def setup_logging():
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="ISO"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

    logging.basicConfig(
        format="%(message)s",
        level=logging.INFO,
        handlers=[
            logging.FileHandler("logs/api.log"),
            logging.StreamHandler()
        ]
    )
```

---

## üîí Security

### API Key Management
```python
from fastapi import HTTPException, Depends, Security
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

security = HTTPBearer()

async def verify_api_key(credentials: HTTPAuthorizationCredentials = Security(security)):
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.PyJWTError:
        raise HTTPException(status_code=401, detail="Invalid API key")

@app.get("/api/stocks/{symbol}")
async def get_stock_data(symbol: str, user=Depends(verify_api_key)):
    # API endpoint implementation
    pass
```

### Rate Limiting
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.get("/api/quotes/{symbol}")
@limiter.limit("10/minute")
async def get_quote(request: Request, symbol: str):
    # Implementation
    pass
```

### CORS Configuration
```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://yourdomain.com", "https://app.yourdomain.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
    expose_headers=["X-RateLimit-Remaining", "X-RateLimit-Reset"]
)
```

---

## üîß Troubleshooting

### Common Issues

#### 1. Data Source Rate Limiting
```python
# Implement exponential backoff
import asyncio
import random

async def fetch_with_retry(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = await httpx.get(url)
            if response.status_code == 429:  # Rate limited
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                await asyncio.sleep(wait_time)
                continue
            return response
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            await asyncio.sleep(2 ** attempt)
```

#### 2. WebSocket Connection Issues
```python
# WebSocket connection manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        
    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
            
    async def broadcast(self, message: str):
        for connection in self.active_connections[:]:  # Copy to avoid modification during iteration
            try:
                await connection.send_text(message)
            except Exception:
                self.disconnect(connection)
```

#### 3. Cache Performance Issues
```bash
# Monitor Redis performance
redis-cli --latency-history -h localhost -p 6379

# Check memory usage
redis-cli info memory

# Monitor slow queries
redis-cli slowlog get 10
```

### Performance Optimization
```python
# Connection pooling for HTTP requests
import asyncio
import aiohttp

class DataSourceClient:
    def __init__(self):
        self.session = None
        
    async def get_session(self):
        if self.session is None:
            connector = aiohttp.TCPConnector(
                limit=100,
                limit_per_host=20,
                keepalive_timeout=300,
                enable_cleanup_closed=True
            )
            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=30)
            )
        return self.session
```

### Debugging Commands
```bash
# Check API health
curl -f http://localhost:8000/health

# Test WebSocket connection
wscat -c ws://localhost:8001/ws

# Monitor container resources
docker stats market-data-api

# Check Redis cache
docker exec -it market-data-redis redis-cli monitor

# View logs
docker-compose logs -f api

# Test load balancing
for i in {1..10}; do curl -s http://localhost/api/health | grep -o '"status":"[^"]*"'; done
```

---

## üìà Performance Benchmarks

- **Latency**: < 50ms average response time
- **Throughput**: 1000+ requests/second
- **Memory**: ~200MB per instance
- **WebSocket**: 1000+ concurrent connections
- **Cache**: 95%+ hit rate for repeated requests
- **Uptime**: 99.9% availability

---

## üÜò Support

- **Issues**: [GitHub Issues](https://github.com/olaitanojo/market-data-api/issues)
- **API Documentation**: [Swagger UI](http://localhost:8000/docs)
- **Community**: [Discord](https://discord.gg/market-data-api)

---

*Last updated: December 2024*
*Version: 2.0.0*
